{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Learning Experiments\n",
    "\n",
    "### 1. Learn diff bewteen Min and Max. `max(seq) - min(seq)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 20) (512,)\n"
     ]
    }
   ],
   "source": [
    "N = 512\n",
    "D = 20\n",
    "x = (np.random.random((N,D)) - 0.5) * 2.0\n",
    "w = np.random.random(D).reshape((D,1))\n",
    "y = (x@w).flatten()\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[0], w, y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_= plt.hist(y, bins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 20, 1)             0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 62ms/step - loss: 2.5253 - mse: 2.5253 - val_loss: 2.2295 - val_mse: 2.2295\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5196 - mse: 2.5196 - val_loss: 2.2297 - val_mse: 2.2297\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5164 - mse: 2.5164 - val_loss: 2.2302 - val_mse: 2.2302\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 2.5140 - mse: 2.5140 - val_loss: 2.2306 - val_mse: 2.2306\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.5125 - mse: 2.5125 - val_loss: 2.2314 - val_mse: 2.2314\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.5106 - mse: 2.5106 - val_loss: 2.2313 - val_mse: 2.2313\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.5092 - mse: 2.5092 - val_loss: 2.2305 - val_mse: 2.2305\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.5080 - mse: 2.5080 - val_loss: 2.2308 - val_mse: 2.2308\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5069 - mse: 2.5069 - val_loss: 2.2301 - val_mse: 2.2301\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.5062 - mse: 2.5062 - val_loss: 2.2293 - val_mse: 2.2293\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.5055 - mse: 2.5055 - val_loss: 2.2295 - val_mse: 2.2295\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5049 - mse: 2.5049 - val_loss: 2.2292 - val_mse: 2.2292\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5041 - mse: 2.5041 - val_loss: 2.2278 - val_mse: 2.2278\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5037 - mse: 2.5037 - val_loss: 2.2268 - val_mse: 2.2268\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5031 - mse: 2.5031 - val_loss: 2.2255 - val_mse: 2.2255\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5022 - mse: 2.5022 - val_loss: 2.2231 - val_mse: 2.2231\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 2.5019 - mse: 2.5019 - val_loss: 2.2227 - val_mse: 2.2227\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.5010 - mse: 2.5010 - val_loss: 2.2176 - val_mse: 2.2176\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.4991 - mse: 2.4991 - val_loss: 2.2144 - val_mse: 2.2144\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.4992 - mse: 2.4992 - val_loss: 2.2066 - val_mse: 2.2066\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.4958 - mse: 2.4958 - val_loss: 2.1975 - val_mse: 2.1975\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.4932 - mse: 2.4932 - val_loss: 2.1919 - val_mse: 2.1919\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 2s 61ms/step - loss: 2.4915 - mse: 2.4915 - val_loss: 2.1843 - val_mse: 2.1843\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.4886 - mse: 2.4886 - val_loss: 2.1643 - val_mse: 2.1643\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.4934 - mse: 2.4934 - val_loss: 2.1276 - val_mse: 2.1276\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.4820 - mse: 2.4820 - val_loss: 2.1159 - val_mse: 2.1159\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.4714 - mse: 2.4714 - val_loss: 2.0974 - val_mse: 2.0974\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.4654 - mse: 2.4654 - val_loss: 2.0693 - val_mse: 2.0693\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.4512 - mse: 2.4512 - val_loss: 2.0490 - val_mse: 2.0490\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.4316 - mse: 2.4316 - val_loss: 2.0200 - val_mse: 2.0200\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.4167 - mse: 2.4167 - val_loss: 1.9826 - val_mse: 1.9826\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 2.3813 - mse: 2.3813 - val_loss: 1.9117 - val_mse: 1.9117\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.3707 - mse: 2.3707 - val_loss: 1.8837 - val_mse: 1.8837\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 2.3138 - mse: 2.3138 - val_loss: 1.8797 - val_mse: 1.8797\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.2884 - mse: 2.2884 - val_loss: 1.8609 - val_mse: 1.8609\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.2685 - mse: 2.2685 - val_loss: 1.8431 - val_mse: 1.8431\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.2402 - mse: 2.2402 - val_loss: 1.8373 - val_mse: 1.8373\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.2517 - mse: 2.2517 - val_loss: 1.8223 - val_mse: 1.8223\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.2170 - mse: 2.2170 - val_loss: 1.8269 - val_mse: 1.8269\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.2128 - mse: 2.2128 - val_loss: 1.8112 - val_mse: 1.8112\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 2.2391 - mse: 2.2391 - val_loss: 1.8021 - val_mse: 1.8021\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 2.1890 - mse: 2.1890 - val_loss: 1.7951 - val_mse: 1.7951\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.1676 - mse: 2.1676 - val_loss: 1.7325 - val_mse: 1.7325\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.1805 - mse: 2.1805 - val_loss: 1.7553 - val_mse: 1.7553\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 2.1390 - mse: 2.1390 - val_loss: 1.7275 - val_mse: 1.7275\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.1566 - mse: 2.1566 - val_loss: 1.7130 - val_mse: 1.7130\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.1237 - mse: 2.1237 - val_loss: 1.7155 - val_mse: 1.7155\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.1135 - mse: 2.1135 - val_loss: 1.7140 - val_mse: 1.7140\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.1064 - mse: 2.1064 - val_loss: 1.7136 - val_mse: 1.7136\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 2s 57ms/step - loss: 2.1100 - mse: 2.1100 - val_loss: 1.7126 - val_mse: 1.7126\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.0819 - mse: 2.0819 - val_loss: 1.6983 - val_mse: 1.6983\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.0754 - mse: 2.0754 - val_loss: 1.6960 - val_mse: 1.6960\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 2.0673 - mse: 2.0673 - val_loss: 1.6894 - val_mse: 1.6894\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.0619 - mse: 2.0619 - val_loss: 1.6882 - val_mse: 1.6882\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 2.0515 - mse: 2.0515 - val_loss: 1.6921 - val_mse: 1.6921\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.0432 - mse: 2.0432 - val_loss: 1.6837 - val_mse: 1.6837\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.0476 - mse: 2.0476 - val_loss: 1.6868 - val_mse: 1.6868\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.0434 - mse: 2.0434 - val_loss: 1.6765 - val_mse: 1.6765\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 2.0266 - mse: 2.0266 - val_loss: 1.6792 - val_mse: 1.6792\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.0253 - mse: 2.0253 - val_loss: 1.6746 - val_mse: 1.6746\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 2s 58ms/step - loss: 2.0150 - mse: 2.0150 - val_loss: 1.6743 - val_mse: 1.6743\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 2.0080 - mse: 2.0080 - val_loss: 1.6724 - val_mse: 1.6724\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 2s 59ms/step - loss: 2.0029 - mse: 2.0029 - val_loss: 1.6693 - val_mse: 1.6693\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 2.0012 - mse: 2.0012 - val_loss: 1.6681 - val_mse: 1.6681\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.9947 - mse: 1.9947 - val_loss: 1.6664 - val_mse: 1.6664\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.9924 - mse: 1.9924 - val_loss: 1.6661 - val_mse: 1.6661\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.9862 - mse: 1.9862 - val_loss: 1.6618 - val_mse: 1.6618\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 1.9715 - mse: 1.9715 - val_loss: 1.6612 - val_mse: 1.6612\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 2s 57ms/step - loss: 1.9652 - mse: 1.9652 - val_loss: 1.6548 - val_mse: 1.6548\n",
      "Epoch 70/100\n",
      " 1/28 [>.............................] - ETA: 1s - loss: 0.8733 - mse: 0.8733"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     14\u001b[0m model \u001b[39m=\u001b[39m create_model(input_dim\u001b[39m=\u001b[39mD)\n\u001b[1;32m---> 15\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit( x,y, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.125\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m hdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(hist\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m     17\u001b[0m hdf\u001b[39m.\u001b[39mplot()\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\7891zb\\Miniconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_model(input_dim):\n",
    "    keras.backend.clear_session()\n",
    "    model = keras.models.Sequential([\n",
    "        tf.keras.layers.Reshape((input_dim, 1),  input_shape=(input_dim,)),\n",
    "        keras.layers.LSTM(1, recurrent_activation=\"relu\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model(input_dim=D)\n",
    "hist = model.fit( x,y, batch_size=16, epochs=100,verbose=1, validation_split=0.125)\n",
    "hdf = pd.DataFrame(hist.history)\n",
    "hdf.plot()\n",
    "hdf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 269ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.86740774],\n",
       "        [-0.44046977],\n",
       "        [-0.75929314],\n",
       "        [ 0.54484475],\n",
       "        [-0.7954091 ]], dtype=float32),\n",
       " array([ 1.39024676, -0.3513331 , -1.51444589,  0.99917448, -1.88631181]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x[:5]), y[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c7e92d8f7cbada54fc4025b4c9b9527ffad52170e7a13f1f1e25daac9570506"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
